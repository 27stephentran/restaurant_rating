{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and preprocess\n",
    "businesses = pd.read_json('trainingdata\\yelp_business.json', lines=True)\n",
    "reviews = pd.read_json('trainingdata\\yelp_review.json', lines=True)\n",
    "users = pd.read_json('trainingdata\\yelp_user.json', lines=True)\n",
    "checkins = pd.read_json('trainingdata\\yelp_checkin.json', lines=True)\n",
    "tips = pd.read_json('trainingdata\\yelp_tip.json', lines=True)\n",
    "photos = pd.read_json('trainingdata\\yelp_photo.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "df = pd.merge(businesses, reviews, how='left', on='business_id')\n",
    "df = pd.merge(df, users, how='left', on='business_id')\n",
    "df = pd.merge(df, checkins, how='left', on='business_id')\n",
    "df = pd.merge(df, tips, how='left', on='business_id')\n",
    "df = pd.merge(df, photos, how='left', on='business_id')\n",
    "\n",
    "# Remove unnecessary features\n",
    "features_to_remove = ['address', 'attributes', 'business_id', 'categories', 'city', 'hours', 'is_open', 'latitude', 'longitude', 'name', 'neighborhood', 'postal_code', 'state', 'time']\n",
    "df.drop(features_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({\n",
    "    'weekday_checkins': 0,\n",
    "    'weekend_checkins': 0,\n",
    "    'average_tip_length': 0,\n",
    "    'number_tips': 0,\n",
    "    'average_caption_length': 0,\n",
    "    'number_pics': 0\n",
    "}, inplace=True)\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = df.drop('stars', axis=1)  # Features\n",
    "y = df['stars']  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4715/4715 [==============================] - 18s 4ms/step - loss: 0.7965 - accuracy: 0.0232 - val_loss: 0.3337 - val_accuracy: 0.0224\n",
      "Epoch 2/10\n",
      "4715/4715 [==============================] - 14s 3ms/step - loss: 0.3942 - accuracy: 0.0231 - val_loss: 0.2993 - val_accuracy: 0.0224\n",
      "Epoch 3/10\n",
      "4715/4715 [==============================] - 14s 3ms/step - loss: 0.3442 - accuracy: 0.0229 - val_loss: 0.2965 - val_accuracy: 0.0224\n",
      "Epoch 4/10\n",
      "4715/4715 [==============================] - 17s 4ms/step - loss: 0.3344 - accuracy: 0.0227 - val_loss: 0.3000 - val_accuracy: 0.0224\n",
      "Epoch 5/10\n",
      "4715/4715 [==============================] - 15s 3ms/step - loss: 0.3273 - accuracy: 0.0227 - val_loss: 0.2932 - val_accuracy: 0.0224\n",
      "Epoch 6/10\n",
      "4715/4715 [==============================] - 13s 3ms/step - loss: 0.3242 - accuracy: 0.0228 - val_loss: 0.2958 - val_accuracy: 0.0224\n",
      "Epoch 7/10\n",
      "4715/4715 [==============================] - 14s 3ms/step - loss: 0.3221 - accuracy: 0.0228 - val_loss: 0.2894 - val_accuracy: 0.0224\n",
      "Epoch 8/10\n",
      "4715/4715 [==============================] - 13s 3ms/step - loss: 0.3205 - accuracy: 0.0228 - val_loss: 0.2909 - val_accuracy: 0.0224\n",
      "Epoch 9/10\n",
      "4715/4715 [==============================] - 13s 3ms/step - loss: 0.3203 - accuracy: 0.0228 - val_loss: 0.2909 - val_accuracy: 0.0224\n",
      "Epoch 10/10\n",
      "4715/4715 [==============================] - 13s 3ms/step - loss: 0.3194 - accuracy: 0.0227 - val_loss: 0.2888 - val_accuracy: 0.0224\n",
      "1179/1179 [==============================] - 2s 2ms/step - loss: 0.2888 - accuracy: 0.0224\n",
      "Mean Squared Error: 0.28876805305480957\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Mean Squared Error:', loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "Predicted rating from 2.14 to 2.0\n"
     ]
    }
   ],
   "source": [
    "''' Input array should contain: \n",
    "'alcohol?' (0 or 1),), \n",
    "'has_bike_parking' (0 or 1),, \n",
    "'takes_credit_cards' (0 or 1), \n",
    "'good_for_kids' (0 or 1),, \n",
    "'take_reservations' (0 or 1),, \n",
    "'has_wifi' (0 or 1), \n",
    "'review_count' (int),, \n",
    "'price_range' (int),, \n",
    "'average_caption_length' (float), \n",
    "'number_pics' (int), \n",
    "'average_review_age' (float), \n",
    "'average_review_length' (float), \n",
    "'average_review_sentiment' (float), \n",
    "'number_funny_votes' (int),\n",
    "'number_cool_votes' (int),\n",
    "'number_useful_votes' (int),\n",
    "'average_tip_length' (float),\n",
    "'number_tips' (int),\n",
    "'average_number_friends' (float), \n",
    "'average_days_on_yelp' (float),\n",
    "'average_number_fans' (float),\n",
    "'average_review_count' (float),\n",
    "'average_number_years_elite' (float),\n",
    "'weekday_checkins' (int),\n",
    "'weekend_checkins' (int)\n",
    "'''\n",
    "input_data = np.array([0, 1, 1, 1, 1, 1, 10, 2, 3, 10, 10, 1200, 0.9, 2, 17, 20, 50, 3, 100, 1800, 15, 200, 2, 1, 1])\n",
    "input_data = input_data.reshape(1, -1)\n",
    "prediction = model.predict(input_data)\n",
    "print(f'Predicted rating from', round(prediction[0][0],2), \"to\", round(prediction[0][0],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dropout\n",
      "......vars\n",
      "...layers\\dropout_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-07-06 14:14:51         2123\n",
      "metadata.json                                  2023-07-06 14:14:51           64\n",
      "variables.h5                                   2023-07-06 14:14:51       165696\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "outfile = open(\"model_with_10epochs.pickle\", \"wb\")\n",
    "pickle.dump(model,outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
